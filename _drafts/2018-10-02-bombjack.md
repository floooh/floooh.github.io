---
layout: post
title: " Bomb Jack!"
---

I wrote a little Bomb Jack arcade emulator last week, mainly to learn
how those early 8-bit arcade machines differed in design from 8-bit home
computers.

Playing arcade games like Bomb Jack as a kid at a summer fair in my home town
was one of those 'life-changing moments' that I only recognized much later as
such. On a typical summer day, after I had spent all my coin budget on arcade
games (usually didn't take very long) I walked home with the head full of
colors and sound effects, trying to figure out how those games worked. And
then spending all my non-school time trying to build rather poor impressions
of those games on my home computer, not unlike a cargo-cultist on a post-WWII
pacific island trying to build a US military radio station from wooden
sticks.

At first I've been playing with the idea of writing a *Pengo* emulator, since
this burned itself even more into my teenage-brain than Bomb Jack (this is my
[teenager cargo-cult version of
Pengo](https://floooh.github.io/tiny8bit/kc85.html?type=kc85_3&snapshot=kc85/pengo.kcc) btw).
But the Pengo arcade hardware would require new chip emulators for sound and
video, while Bomb Jack only needs parts I already have working (Z80 as CPU
and the AY-3-8910 for sound), so I went for Bomb Jack first.

Bomb Jack was also a good opportunity to finally add NMI (non-maskable interrupt)
support to my Z80 emulator. None of the Z80 machines I emulated before
used NMIs, and it didn't make much sense to implement a feature when I have
no way to test whether it even works.

If you don't know what Bomb Jack is, it looks like this (not sure if I got the
screen aspect ratio right):

![Bomb Jack Screenshot]({{ site.url }}/images/bombjack_1.png)

...the final outcome of this blog post is here (as the WebAssembly version):

[https://floooh.github.io/tiny8bit/bombjack.html](https://floooh.github.io/tiny8bit/bombjack.html)

After the boot sequence has finished and the hiscore screen appears,
press **1** to insert coins, and than **Enter** (or any other key
except arrows and space) to start a game.

In the game, use **arrows keys** for direction, and **space** to jump. While
in the air tap **space** to reduce falling speed.

The source code is here: 

[https://github.com/floooh/chips-test/blob/master/examples/sokol/bombjack.c](https://github.com/floooh/chips-test/blob/master/examples/sokol/bombjack.c)

This uses the [chips headers](https://github.com/floooh/chips) to provide
the Z80 and AY-3-8910 emulations, and the [sokol headers](https://github.com/floooh/sokol) as cross-platform wrapper (application
entry, rendering, input and audio).

Btw, the size of the WebAssembly version is interesting. Basically, the
compressed emulator with embedded ROMs is as big as the uncompressed ROMs alone:

Running the emulator downloads around 113 KB overall:

- bombjack.html+style.css+emsc.js:      2.5 KB
- bombjack.js (emscripten runtime):     26.8 KB
- bombjack.wasm (includes the ROMs):    83.6 KB

This is with the normal gzip-compression applied by the github web servers.

And those 113 KBytes is alomst exactly the size of the uncompressed game
ROMs alone (112 KBytes). The ROMs compress to about 57 KBytes, all of this
data is embedded in the bombjack.wasm file, so the compressed
WebAssembly byte code *without* the embedded ROM data would be under 30 KBytes
(84 - 57), quite impressive IMHO :)

It's possible to shave off a couple more KBytes both from the .wasm as
well as the emscripten runtime file by replacing the WebGL rendering with
dumping the image data into a 2D canvas, and further by deactivating a few
emscripten features that the Bombjack emulator isn't using, but that will be
an experiment for another time :)

## Step 1: Research

"Research" is a grand word for typing "Bombjack arcade hardware specs" into
Google ;)

Compared to popular 80's home computers (or even obscure Eastern European
computers, which often still have active communities), there's very little
information for Bomb Jack out there. 

The two useful pieces of information I found are the original [hardware
schematics](https://github.com/floooh/emu-info/blob/master/misc/bombjack-schematics.pdf),
and of course the [MAME emulator source
code](https://github.com/mamedev/mame/blob/master/src/mame/drivers/bombjack.cpp).

There's also a project which implements [Bomb Jack in an FGPA](http://papilio.cc/index.php?n=Playground.BombJack) 
where the VHDL source yielded some details where the schematics miss information.

The MAME sources may be a bit hard to grok, because the arcade emulations
are usually just a bunch of macros describing how the different hardware
parts interact, but there's little actual *source code* to read.

But the macro-hardware-descriptions, and especially the comments are still
very helpful to understand how the hardware works, and in those places where
it all becomes a bit too obscure (for instance the [video decoding
part](https://github.com/mamedev/mame/blob/master/src/mame/video/bombjack.cpp))
a bit of trial and error, and running the finger through the hardware
schematics is enough to clear up the confusion.

## Hardware Overview

The most interesting feature of the Bomb Jack hardware is that it's actually
**two computers** duck-taped together, there's a **main board** with a Z80 CPU
and the video decoding hardware, and a separate **sound board** with its own
Z80 CPU and 3 (yes, three!!) AY-3-8910 sound chips.

The video decoding hardware on the main board isn't implemented in an
integrated circuit, instead it's lots and lots of little general-purpose chips
hardwired together. For the emulator I took a shortcut here: instead of emulating
the video decoding hardware piece by piece, I only emulated it's behaviour by
creating the right visual output from the inputs, without caring too much
how the hardware inbetween actually works.

This shortcut-approach is totally fine for a dedicated arcade machine which
only ever needs to run one program. If the game looks and feels right, the
emulation is "good enough".

This is an important difference to most home computer emulators: some games
demand a more precise emulation than others, and machines like the C64 or
Amstrad CPC need a very precise emulation down to the clock cycle for the
video systems for some games and graphics demos to work.

It also means that my existing CPU and sound-chip emulators are a
bit overkill for Bomb Jack, for instance the Z80 CPU is running with
machine-cycle granularity when a simpler and faster instruction-granularity
would definitely be good enough.

## The Main Board

Usually the first thing I try to find out when writing a new emulator
is what integrated chips are used, and the memory configuration (where are the ROM
and RAM areas, the video memory, and special IO addresses or ports).

The Bomb Jack main board only has one "big chip": the Z80 CPU running
at 4 MHz. The entire remaing space on the main board is dedicated to
the video decoding hardware (besides RAM and ROM chips of course).

The 16-bit address space looks like this:

- **0000..7FFF**: 32 KByte ROM
- **8000..8FFF**: 4 KByte general purpose RAM
- **9000..93FF**: 1 KByte video RAM
- **9400..97FF**: 1 KByte color RAM
- **9820..987F**: 96 bytes sprite RAM
- **9C00..9CFF**: 256 bytes color palette RAM
- **9E00, B000..B005, B800**: IO ports
- **C000..DFFF**: 8 KByte ROM

The IO ports look like this, some of the ports are write-only,
some are read-only, and some have different functions when read or written:

- **9E00**:     write: the current background-image number, read: ---
- **B000**:     read: player 1 joystick state, write: NMI enable/disable mask
- **B001**:     read: player 2 joystick state, write: ---
- **B002**:     read: coins and start buttons, write: ---
- **B003**:     write: CPU watchdog, read: ---
- **B004**:     read: dip-switches 1, write: flip screen
- **B005**:     read: dip-switches 2, write: ---
- **B800**:     write: command to sound board, read: ---

The IO ports are described in more detail below.

There's a few noteworthy things:

- There's a LOT of ROM (40 KBytes), and not a lot of RAM (about 7 KBytes, with
only 4 KByte 'general purpose RAM')
- There's only 2 KBytes for 'display RAM', divided into 2 chunks of 1 KByte,
this looks very small for driving a colorful 256x256 display which appears to have
per-pixel colors
- It's a memory-mapped-IO system!

Memory-mapped-IO is a bit unusual for a Z80 machine, since one of the
defining features of the Z80 is the separate 16-bit address space for device-IO,
so that no precious memory address space needs to be wasted. Memory mapped IO
is typically a feature found on computers with a 6502 CPU.

A quick look into the schematics confirms this: There's no IORQ pin anywhere
to be found on the main board CPU, only the MREQ pin is connected (which
is used to initiate a memory read or write):

![Bomb Jack IORQ]({{ site.url }}/images/bombjack_iorq.png)

This means I don't need to care about IO requests in the emulator's mainboard CPU
tick function at all, only about memory requests.

While snooping around the schematics, there's another interesting mainboard CPU detail:

Only the NMI pin is connected, while the INT pin is always kept high/inactive (meaning
no 'regular' maskable interrupts will happen, only non-maskable interrupts):

![Bomb Jack IORQ]({{ site.url }}/images/bombjack_nmi.png)

This is also quite unusual for a Z80 machine. All Z80-based home computers
I've seen so far had it the other way around, they only used maskable
interrupts, and never non-maskable interrupts. The maskable interrupt
handling on the Z80 is very flexible and a big improvement over the rather
primitive interrupt system of it's 'illegitimate father', the Intel 8080, or
its rival, the MOS 6502. But this improved flexibility is also more complex
to implement in hardware (unless other Z80-family chips like the CTC or PIO are
used, which have the complex interrupt 'daisy-chain' protocol already baked in).

The Z80 NMI is 'edge-triggered', while regular INTs are 'level-triggered'.
This means the Z80 only 'sees' an NMI when the NMI pin state changes from
inactive to active, but as long as the NMI pin remains active, or goes
from active to inactive, no additional NMI will be triggered.

This is different from the INT pin which is 'level-triggered'. Whenever the
CPU detects that the INT pin is active, and interrupts are enabled, the
interrupt service protocol will be invoked (most of the complexity of the
Z80's maskable interrupt protocol comes from the fact that a higher-level
interrupt may intercept a lower-level device's interrupt service routine).

The edge-triggered detection of the NMI mainly has some implications for how
the Bomb Jack interrupt service routines are implemented. If the NMI pin goes
from inactive to active **while currently in the interrupt service routine**,
a new NMI would be triggered and the interrupt service routine will be called
again, which is most likely *not* what is intended.

This was a bit of a head-scratcher when implementing the emulator, since the
NMI is crucial both for the mainboard- and soundboard-code, but the hardware
activates and deactivates the NMI pin slightly differently on the mainboard
and soundboard (more on that below in the section that deals with the
communication between the mainboard and soundboard).

Ok, enough with the hardware details for now, onward to the emulator!

## The Boot Sequence 

The next step after figuring out the memory configuration is to hook up the
CPU to the memory map, write some adhoc visualization of the video
memory content, and start ticking the CPU.

And surprisingly, this crude approach is often enough to run through the
boot sequence and get *something* on screen. For the Bomb Jack emulator I
simply took the content of the 1 KByte video memory at the range 0x9000 to
0x93FF as a 32x32 byte matrix, and when the byte is 0 render a black 8x8
pixel block, otherwise a white pixel block.

Then simply start the emulated CPU and hope for the best. And behold! Something
recognizable appears:

![Bomb Jack Boot 1]({{ site.url }}/images/bombjack_boot_1.png)
![Bomb Jack Boot 2]({{ site.url }}/images/bombjack_boot_2.png)

The left image looks a lot like the hardware testing screen during boot, and
the right image like the hiscore screen that appears when the boot
sequence is over:

![Bomb Jack Boot 3]({{ site.url }}/images/bombjack_boot_3.png)
![Bomb Jack Boot 4]({{ site.url }}/images/bombjack_boot_4.png)

...but 90 degrees rotated (which figures because arcade cabinets often had
the screen in vertical 'portrait mode' orientation).

Ok very promising start! 

The first small fix I did was adding a portrait mode at the end of the
render pipeline because my head started to hurt.

The next step would be figuring out how to turn
those white blocks into colored pixels... (huuuge jump now, the details
are described below in the section on video decoding).

Ok... at first everything went quite smoothly, the test screen during boot had
pixels and colors (later I noticed that the color decoding was all wrong, but
anyway):

![Bomb Jack Boot 5]({{ site.url }}/images/bombjack_boot_6.png)

But where the hiscore screen should appear I ended up with a black screen.
Hacking the background color to 'not black' revealed that the pixels are rendered,
but the color palette was set to all black. Hmm...

![Bomb Jack Boot 5]({{ site.url }}/images/bombjack_boot_5.png)

After staring at this screen for a few minutes, I remembered that some colors
on the hiscore screen were animated, and when there's animation there needs
to be some timer, and the obvious time source in this hardware config would be the
display's VSYNC signal, and the VSYNC is hooked up to the CPU's NMI pin (or
rather the VBLANK, which is the short duration between the VSYNC signal and the
cathode ray tube beam travelling back to the top-left corner).

And I didn't have implemented any of this yet...

On the next evening, after I had added a first version of the NMI handling
to the Z80 emulation and hooked this up to an adhoc vsync/vblank counter
in the mainboard's CPU tick function, a lot of things suddenly started to
happen!

First, the hiscore screen had colors, and some of them were animated:

![Bomb Jack NMI 1]({{ site.url }}/images/bombjack_nmi_1.png)

And after a few seconds, more exciting things happened! The hiscore screen
disappeared, and a weird rendition of the first map showed up. This was
clearly the arcade cabinet's attract mode, I could see the first level, and
some color-animated bombs which disappeared as an imaginary Bomb Jack jumped
around the map collecting those bombs:

![Bomb Jack NMI 2]({{ site.url }}/images/bombjack_nmi_2.png)

Colors were still totally wrong, but nevertheless: PROGRESS!

This was the right time to take care of the rest of the video decoding:

## The Video Hardware

At first glance the Bomb Jack video hardware looks very powerful for 
an 8-bit machine from 1984: it has a 256x256 display (ok this isn't much
to write home about) up to 128 colors on screen (out of 4096), a per-pixel
color resolution, and up to 24 per-pixel colored hardware sprites (*this*
is the part to write home about).

8-bit home computers of the same time had about the same display resolution,
but with lots of restrictions when it comes to colors, those restrictions can
be seen nicely when comparing the Bomb Jack ports for the ZX Spectrum and
Amstrad CPC with the Arcade version:

The ZX Spectrum version has a pretty good display resolution, but very few
colors, and it suffers from the Spectrum's typical 'color clash' effect
(although the developers did a pretty good job to not make this too
apparent):

![Bomb Jack ZX]({{ site.url }}/images/bombjack_zx.png)

The Amstrad CPC version is more colorful, but in order to get more colors
they had to switch to a low-resolution display mode, with the result
that the Bomb Jack and monster sprites are a lowres pixel mess:

![Bomb Jack CPC]({{ site.url }}/images/bombjack_cpc.png)

Compare that with the Arcade version which has about the same pixel
resolution as the ZX Spectrum, but with many more colors *and* 
a per-pixel color resolution:

![Bomb Jack Arcade]({{ site.url }}/images/bombjack_arcade.png)

Now the interesting thing is that the arcade version doesn't have better
graphics because it runs on more powerful hardware (it doesn't), but 
the design-focus for the hardware designers was much more narrow. They
could build a machine for a very specific type of game instead of an 
universal (home) computer which needs to run all sorts of applications
and games.

Let's find out how the video hardware works:

## The 3 Display Layers

The final Bomb Jack video output is composed from 3 layers, a background
layer which provides a background image, a foreground layer with the non-moving
elements of a map (text, platforms and bombs), and the sprite layer (for all the
moving stuff, Bomb Jack himself, and the various monsters and graphical
effects):

![Bomb Jack Background]({{ site.url }}/images/bombjack_bg.png)

![Bomb Jack Foreground]({{ site.url }}/images/bombjack_fg.png)

![Bomb Jack Sprites]({{ site.url }}/images/bombjack_sprites.png)

The background layer is built from **16x16** pixel tiles. All background image
data is hardwired in ROMs, the only thing the software can do
is switch between different background images (by writing a number between
0 and 7 into address 0x9E00, where zero means 'no background image displayed').

The advantage of building the background images from tiles is that identical
tiles can be reused, so that less image data needs to be stored in ROMs. Note
how the blue sky, parts of the pyramid and the sand below the pyramid use 
identical tiles:

![Bomb Jack Background Tiles]({{ site.url }}/images/bombjack_bg_tiles.png)

The foreground layer is also tiled, but uses smaller 8x8 tiles. The other
important difference to the background layer is that the tile maps are not
in ROM but in RAM, so that the CPU can be used to 'draw' the foreground layer
(this is what the 1 KByte 'video RAM' and 1 KByte 'color RAM' is for):

![Bomb Jack Background Tiles]({{ site.url }}/images/bombjack_fg_tiles.png)



## The 8x8 Tile Decoder

The core idea of the entire video decoding is an efficient 'hardware
image decompression' for 8x8-pixel tiles. Those 8x8 tiles are the
building blocks for everything that's displayed.

In general the tile decoder works like a bitmap-font renderer which turns ASCII code
into 8x8 pixel characters.

The ingredients for this 'tile decoder' are:

- a color palette with 128 entries
- a 'tile code' (this is basically the 'ASCII code' in the font renderer)
- a 4-bit color-value per tile
- three 'tile-sheet-bitplanes' (basically the font data for the tiles, split up 
into three bitplanes)

All those numbers are important:

- the color palette size is 128, so we need **7 bits** to select a color from the palette
- there are **3 bit**planes for the per-tile pixel data
- there is a **4 bit** color value per tile

    3 + 4 = 7

The following drawing illustrates how the different parts play together:

![Bomb Jack Tile Decoding]({{ site.url }}/images/bombjack_8x8.jpg)

