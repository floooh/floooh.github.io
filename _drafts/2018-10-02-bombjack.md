---
layout: post
title: " Bomb Jack"
---

**TL;DR**: what I learned about the Bomb Jack arcade hardware while writing
an emulator for it.

I wrote a little Bomb Jack arcade emulator recently, mainly to learn
how those early 8-bit arcade machines differed in design from 8-bit home
computers.

Playing arcade games like Bomb Jack as a kid at the summer fair in my home
town was one of those 'life-changing moments' that I only recognized much
later as such. On a typical summer day, after I had spent all my coin budget
on arcade games (usually didn't take very long) I walked home with the head
full of colors and sound effects, trying to figure out how those games
worked. And then for the rest of the year spend all my after-school time
trying to build rather poor impressions of those arcade games on my home
computer, not unlike a cargo-cult worshipper on a post-WWII pacific island trying to
build a US military radio station from wooden sticks.

At first I've been playing with the idea of writing a *Pengo* emulator, since
this burned itself even more into my teenager-brain than Bomb Jack (this is my
[cargo-cult version of
Pengo](https://floooh.github.io/tiny8bit/kc85.html?type=kc85_3&snapshot=kc85/pengo.kcc) btw).
But the Pengo arcade hardware would require new chip emulators for sound and
video, while Bomb Jack only needs parts I already had working (Z80 as CPU
and the AY-3-8910 for sound), so I went for Bomb Jack first.

Bomb Jack was also a good opportunity to finally add NMI (non-maskable interrupt)
support to my Z80 emulator. None of the Z80 machines I emulated before
used NMIs, and it didn't make much sense to implement a feature when I have
no way to test whether it even works.

If you don't know what Bomb Jack is, it looks like this (not sure if I got the
screen aspect ratio right):

![Bomb Jack Screenshot]({{ site.url }}/images/bombjack_1.png)

...you can check out the WebAssembly version of the emulator here:

[https://floooh.github.io/tiny8bit/bombjack.html](https://floooh.github.io/tiny8bit/bombjack.html)

After the boot sequence has finished and the hiscore screen appears,
press **1** to insert coins, and than **Enter** (or any other key
except arrows and space) to start a game.

In the game, use **arrows keys** for direction, and **space** to jump. While
in the air tap **space** to reduce falling speed.

The source code is here: 

[https://github.com/floooh/chips-test/blob/master/examples/sokol/bombjack.c](https://github.com/floooh/chips-test/blob/master/examples/sokol/bombjack.c)

This uses the [chips headers](https://github.com/floooh/chips) to provide
the Z80 and AY-3-8910 emulations, and the [sokol headers](https://github.com/floooh/sokol) as cross-platform wrapper (application
entry, rendering, input and audio).

## Step 1: Research

"Research" is a grand word for typing "Bombjack arcade hardware specs" into
Google ;)

Compared to popular 80's home computers (or even obscure Eastern European
computers, which often still have active communities), there's very little
information for Bomb Jack on the web.

The two useful pieces of information I found are the original [hardware
schematics](https://github.com/floooh/emu-info/blob/master/misc/bombjack-schematics.pdf),
and of course the [MAME emulator source
code](https://github.com/mamedev/mame/blob/master/src/mame/drivers/bombjack.cpp).

There's also a project which implements [Bomb Jack in an FGPA](http://papilio.cc/index.php?n=Playground.BombJack) 
where the VHDL source yielded some details where the schematics miss information.

The MAME sources may be a bit hard to grok, because the arcade emulations
are usually just a bunch of macros describing how the different hardware
parts interact, but there's little actual *source code* to read.

But the macro-hardware-descriptions, and especially the comments are still
very helpful to understand how the hardware works, and in those places where
it all becomes a bit too obscure (for instance the [video decoding
part](https://github.com/mamedev/mame/blob/master/src/mame/video/bombjack.cpp))
a bit of trial and error, and running the finger through the hardware
schematics is enough to clear up the confusion.

## Hardware Overview

The most interesting feature of the Bomb Jack hardware is that it's actually
**two computers** duck-taped together, there's a **main board** with a Z80 CPU
and the video decoding hardware, and a separate **sound board** with its own
Z80 CPU and 3 (yes, three!!) AY-3-8910 sound chips.

The video decoding hardware on the main board isn't implemented in an
integrated circuit, instead it's lots and lots of little general-purpose
chips (taking up 6 of the 10 schematics pages). For the emulator I took a
shortcut here: instead of emulating the video decoding hardware piece by
piece, I only emulated it's behaviour by creating the right visual output
from the inputs, without caring too much how the hardware inbetween actually
works.

This shortcut-approach is totally fine for a dedicated arcade machine which
only ever needs to run one program. If the game looks and feels right, the
emulation is "good enough".

This 'shortcut approach' is also an important difference to most home
computer emulators: some games demand a more precise emulation than others,
for instance machines like the C64 or Amstrad CPC need a very precise emulation down
to the clock cycle for the video systems for some games and graphics demos to
work.

It also means that my existing CPU and sound-chip emulators are a
bit overkill for Bomb Jack, for instance the Z80 CPU is running with
machine-cycle granularity when a simpler and faster instruction-granularity
would definitely be good enough.

## The Main Board

Usually the first thing I try to find out when writing a new emulator the
memory map (where are the ROM and RAM areas, the video memory, and
special IO addresses or ports).

The Bomb Jack only has one 'interesting' chip, the Z80 CPU running at at 4
MHz. The entire remaing space on the main board is dedicated to the video
decoding hardware (besides RAM and ROM chips of course).

The 16-bit address space looks like this:

- **0000..7FFF**: 32 KByte ROM
- **8000..8FFF**: 4 KByte general purpose RAM
- **9000..93FF**: 1 KByte video RAM
- **9400..97FF**: 1 KByte color RAM
- **9820..987F**: 96 bytes sprite RAM
- **9C00..9CFF**: 256 bytes color palette RAM
- **9E00, B000..B005, B800**: IO ports
- **C000..DFFF**: 8 KByte ROM

The IO port area looks like this, some of the ports are write-only,
some are read-only, and some have different functions when read or written:

- **9E00**:     write: the current background-image number, read: ---
- **B000**:     read: player 1 joystick state, write: NMI enable/disable mask
- **B001**:     read: player 2 joystick state, write: ---
- **B002**:     read: coins and start buttons, write: ---
- **B003**:     write: CPU watchdog, read: ---
- **B004**:     read: dip-switches 1, write: flip screen
- **B005**:     read: dip-switches 2, write: ---
- **B800**:     write: command to sound board, read: ---

There's a few noteworthy things:

- There's a LOT of ROM (40 KBytes), and not a lot of RAM (about 7 KBytes, with
only 4 KByte 'general purpose RAM')
- There's only 2 KBytes for 'display RAM', divided into 2 chunks of 1 KByte,
this looks very small for driving a colorful 256x256 display which appears to have
per-pixel colors
- It's a memory-mapped-IO system!

Memory-mapped-IO is a bit unusual for a Z80 machine, since one of the
defining features of the Z80 is the separate 16-bit address space for device-IO,
so that no precious memory address space needs to be wasted. Memory mapped IO
is typically a feature found on computers with a 6502 CPU.

A quick look into the schematics confirms this: There's no IORQ pin anywhere
to be found on the main board CPU, only the MREQ pin is connected (which
is used to initiate a memory read or write):

![Bomb Jack IORQ]({{ site.url }}/images/bombjack_iorq.png)

This means I don't need to care about IO requests in the emulator's mainboard CPU
tick function at all, only about memory requests.

While snooping around the schematics, there's another interesting mainboard CPU detail:

Only the NMI pin is connected, while the INT pin is always kept high/inactive (meaning
no 'regular' maskable interrupts will happen, only non-maskable interrupts):

![Bomb Jack IORQ]({{ site.url }}/images/bombjack_nmi.png)

This is also quite unusual for a Z80 machine. All Z80-based home computers
I've seen so far had it the other way around, they only used maskable
interrupts, and never non-maskable interrupts. The maskable interrupt
handling on the Z80 is very flexible and a big improvement over the rather
primitive interrupt system of it's 'illegitimate father', the Intel 8080, or
its rival, the MOS 6502. But this improved flexibility is also more complex
to implement in hardware (unless other Z80-family chips like the CTC or PIO are
used, which have the complex interrupt 'daisy-chain' protocol already baked in).

The Z80 NMI is 'edge-triggered', while regular INTs are 'level-triggered'.
This means the Z80 only 'sees' an NMI when the NMI pin state changes from
inactive to active, but as long as the NMI pin remains active, or goes
from active to inactive, no additional NMI will be triggered.

This is different from the INT pin which is 'level-triggered'. Whenever the
CPU detects that the INT pin is active, and interrupts are enabled, the
interrupt service protocol will be invoked (most of the complexity of the
Z80's maskable interrupt protocol comes from the fact that a higher-level
interrupt may intercept a lower-level device's interrupt service routine).

The edge-triggered detection of the NMI mainly has some implications for how
the Bomb Jack interrupt service routines are implemented. If the NMI pin goes
from inactive to active **while currently in the interrupt service routine**,
a new NMI would be triggered and the interrupt service routine will be called
again, which is most likely *not* what is intended.

This was a bit of a head-scratcher when implementing the emulator, since the
NMI is crucial both for the mainboard- and soundboard-code, but the hardware
activates and deactivates the NMI pin slightly differently on the mainboard
and soundboard (more on that below in the section that deals with the
communication between the mainboard and soundboard).

Ok, enough with the hardware details for now, onward to the emulator!

## The Boot Sequence 

The next step after figuring out the memory configuration is to hook up the
CPU to the memory map, write some adhoc visualization of the video
memory content, and start ticking the CPU.

And surprisingly, this crude approach is often enough to run through the
boot sequence and get *something* on screen. For the Bomb Jack emulator I
simply took the content of the 1 KByte video memory at the range 0x9000 to
0x93FF as a 32x32 byte matrix, and when the byte is 0, render a black 8x8
pixel block, otherwise a white pixel block.

Then simply start the emulated CPU and hope for the best. And behold! Something
recognizable appears:

![Bomb Jack Boot 1]({{ site.url }}/images/bombjack_boot_1.png)
![Bomb Jack Boot 2]({{ site.url }}/images/bombjack_boot_2.png)

The left image looks a lot like the hardware testing screen during boot, and
the right image like the hiscore screen that appears when the boot
sequence is over:

![Bomb Jack Boot 3]({{ site.url }}/images/bombjack_boot_3.png)
![Bomb Jack Boot 4]({{ site.url }}/images/bombjack_boot_4.png)

...but 90 degrees rotated (which figures because arcade cabinets often had
the screen in vertical 'portrait mode' orientation).

Ok very promising start! 

The first small fix I did was rendering the output image 90 degree rotated
because my head started to hurt.

The next step would be figuring out how to turn
those white blocks into colored pixels... (huuuge jump now, the details
are described below in the section on video decoding).

Ok... at first everything went quite smoothly, the test screen during boot had
pixels and colors (later I noticed that the color decoding was all wrong, but
anyway):

![Bomb Jack Boot 5]({{ site.url }}/images/bombjack_boot_6.png)

But where the hiscore screen should appear I ended up with a black screen.
Hacking the background color to 'not black' revealed that the pixels are rendered,
but the color palette was set to all black. Hmm...

![Bomb Jack Boot 5]({{ site.url }}/images/bombjack_boot_5.png)

After staring at this screen for a few minutes, I remembered that some colors
on the hiscore screen were animated, and when there's animation there needs
to be some timer, and the obvious time source in this hardware config would be the
display's VSYNC signal, and the VSYNC is hooked up to the CPU's NMI pin (or
rather the VBLANK, which is the short duration between the VSYNC signal and the
cathode ray tube beam travelling back to the top-left corner).

And I didn't have implemented any of this yet...

On the next evening, after I had added a first version of the NMI handling
to the Z80 emulation and hooked this up to an adhoc vsync/vblank counter
in the mainboard's CPU tick function, a lot of things suddenly started to
happen!

First, the hiscore screen had colors, and some of them were animated:

![Bomb Jack NMI 1]({{ site.url }}/images/bombjack_nmi_1.png)

And after a few seconds, more exciting things happened! The hiscore screen
disappeared, and a weird rendition of the first map showed up. This was
clearly the arcade cabinet's attract mode, I could see the first level, and
some color-animated bombs which disappeared as an imaginary Bomb Jack jumped
around the map collecting those bombs:

![Bomb Jack NMI 2]({{ site.url }}/images/bombjack_nmi_2.png)

Colors were still totally wrong, but nevertheless: PROGRESS!

This was the right time to take care of the rest of the video decoding:

## The Video Hardware

At first glance the Bomb Jack video hardware looks very powerful for 
an 8-bit machine from 1984: even though it only has a 256x256 pixel
resolution, it can display 128 (out of 4096) colors at the same time,
and render up to 24 hardware sprites (16x16 or 32x32 pixels big), all
with per-pixel colors.

8-bit home computers of the same era had about the same display resolution,
but with lots of restrictions when it comes to colors, those restrictions can
be seen nicely when comparing the Bomb Jack versions for the ZX Spectrum and
Amstrad CPC with the Arcade version:

The [ZX Spectrum version](https://floooh.github.io/tiny8bit/zx.html?file=zx/bombjack_zx.z80&joystick=kempston&type=zx48k) 
has a pretty good pixel resolution 256x192), but very
few colors, and it suffers from the Spectrum's typical 'color clash' effect
(although the developers did a pretty good job to not make this too
obvious):

![Bomb Jack ZX]({{ site.url }}/images/bombjack_zx.png)

The [Amstrad CPC version](https://floooh.github.io/tiny8bit/cpc.html?file=cpc/bomb_jack.sna&joystick=true) 
is more colorful, but in order to get more colors
they had to switch to a low-resolution display mode (160x200), with the result
that Jack and the monster are a lowres pixel mess:

![Bomb Jack CPC]({{ site.url }}/images/bombjack_cpc.png)

Compare that with the Arcade version which has about the same pixel
resolution as the ZX Spectrum, but with many more colors *and* 
a per-pixel color resolution:

![Bomb Jack Arcade]({{ site.url }}/images/bombjack_arcade.png)

Now the interesting part is that the arcade version doesn't have better
graphics because it runs on more powerful hardware (it has more ROM to store
more image data, but the 'computing power' is rouhghly the same), instead the
hardware designers could focus on building a specialized machine for one
specific type of game, they didn't have to create a flexible and general
purpose home computer.

Here's how the display hardware works (at least my high-level interpretation
of it):

## The 3 Display Layers

The final Bomb Jack video output is composed from 3 layers: background layer,
foreground layer and sprite layer.

This layer system has 2 main advantages:

- it implements a fairly clever hardware image compression to generate
a colorful "high-resolution" image from very little data
- it drastically reduces the amout of CPU work necessary to update
dynamic elements on the screen (even at 4 MHz, an 8-bit CPU by far doesn't
have enough performance to move that much stuff around on a 256x256 
display at 60 Hz)

The video hardware is fairly different from what I've seen on 8-bit home
computers, but since MAME has implemented generic helper classes for this
sort of hardware I assume it was fairly common on arcade machines.

### The Background Layer

The background layer can render 1 of 4 predefined background images hardwired
into ROM. The hardware actually seems to be capable of rendering 7 different
images, but the game only uses 4. I was secretly hoping to find previously
undiscovered image data in the ROMs. But alas, there aren't any (and I probably
wasn't the first one to look either)

This is what the background layer for the first map looks like without the other two layers:

![Bomb Jack Background]({{ site.url }}/images/bombjack_bg.png)

The background layer is built from **16x16** pixel tiles.

The advantage of building the background images from tiles is that identical
tiles can be reused, so that less per-pixel data needs to be stored in ROMs. Note
how the blue sky, parts of the pyramid and the sand below the pyramid use 
identical tiles:

![Bomb Jack Background Tiles]({{ site.url }}/images/bombjack_bg_tiles.png)

The background layer hardware implements another trick to save some memory,
tiles can be flipped horizontally. I almost didn't implement this because 
I assumed that the software doesn't use this hardware feature, until I 
noticed a subtile bug in the 3rd map background:

![Bomb Jack Background 3]({{ site.url }}/images/bombjack_bg_3.png)

It seems like this is the only place in the entire game where background tile
flipping is used though.

### The Foreground Layer:

On top of the background layer is a 'foreground layer', which renders any
non-movable parts of the screen that must still be updateable by the CPU
(mainly text, platforms and bombs). The layout is read from RAM (the 1 KB
video RAM and 1 KB color RAM chunks).

This is what the isolated foreground layer looks like for the first map:

![Bomb Jack Foreground]({{ site.url }}/images/bombjack_fg.png)

The foreground layer is also tiled (just like the background layer), but uses
smaller 8x8 tiles:

![Bomb Jack Background Tiles]({{ site.url }}/images/bombjack_fg_tiles.png)

The main advantage of keeping background and foreground in separate layers is
that the CPU doesn't need to care about storing and restoring background
pixels when foreground elements are created or removed.

### The Sprite Layer

Finally on top of the forground layer, the hardware sprites are rendered.
Everything that's moving around on screen is done with sprites.
The Bomb Jack hardware can render up to 24 sprites, where each sprite
can be either 16x16 or 32x32 pixels, and sprites can be positioned 
with pixel resolution:

![Bomb Jack Sprites]({{ site.url }}/images/bombjack_sprites.png)


## The 8x8 Tile Decoder

At the heart of the video decoding hardware is a color palette with 
128 entries and an 8x8-pixel tile decoder. The job of the tile decoder
is to generate a 7-bit color palette index for each of the 64 pixels
in a tile.

Those 8x8 tiles are the building blocks for everything on screen, the 16x16
background tiles, 8x8 foreground tiles, and the 16x16 or 32x32 hardware
sprites.

Here's a functional diagram of this 8x8 tile decoder for the foreground
layer rendering (as far as I understood it):

![Bomb Jack Tile Decoding]({{ site.url }}/images/bombjack_8x8.jpg)

Here's a top-to-bottom explanation of the diagram:

- The decoding process starts at the top by reading a 'tile code' byte from the video RAM
(organized as a 32x32 matrix of tile codes), and a separate byte from
the color RAM (also a 32x32 matrix).
- The tile code is used as index to lookup 3 separate pixel bitplanes, those
pixel bitplanes are always stored in ROM (you can think of the pixel bitplanes
as font data or sprite sheets). Each of the layers has its own tile ROMs, and
those ROMs are only visible to the decoding hardware, not to the CPU
(so they don't take up valuable CPU address space).
- A single pixel bitplane consists of 8 bytes per tile, with each byte
holding 8 pixels (one bit per pixel). Since the pixel data for each tile is
built from 3 bitplanes this means an 8x8 tile requires 24 bytes of ROM data
to describe its appearance (3 bits per pixel).
- For each of the 64 pixels in a tile, a 7-bit value is constructed. The lower
3 bits are provided by the tile bitplanes read from the tile ROMs, and the higher
4 bits are provided by the color value byte. This basically means that each tile
can select one of 16 'slots' from the color palette (with each slot having 8 colors),
and each pixel of the tile can have one of the 8 slot colors.
- This 7-bit index built from bitplanes and tile-color-value is used to
lookup a 12-bit color value from the color palette. The color palette is
located in RAM and can be manipulated by the CPU (as far as I have seen the
video-, color- and palette-RAMs are write-only, at least the CPU never does
read-accesses on those areas).

This is the basic tile decoding that's used by each of the 3 display layers,
but each layer works a little bit different:

- The foreground layer can actually render 512 different 8x8 tiles, but this
requires 9-bit tile codes, while the video RAM only provides one 8-bit bytes
per tile. The 9th bit is 'borrowed' from the color RAM value (since only 4
bits of the color RAM value is used to build the color palette index, there
are 4 bits free for other purposes). If the 3 bits from the 8x8 tile bitplanes
are all zero, the foreground pixel is transparent, and the background pixel
'peeks through'.
- The background layer uses 16x16 tiles, so it only needs 16x16=256 tile code
values and 256 color values to describe one background image in the background
image ROM (512 bytes per image). The twist is though that the 16x16 pixel bitplanes
are layed out as four 8x8 tiles (so each background tile requires 96 bytes in
the tile ROMs), so that the same 8x8 tile decoder hardware can
be used. As mentioned above, background
tiles can be horizontally flipped, this is controlled with one of the 'spare'
color value bits: if bit 7 of the color value is set, the tile will be flipped.
- Each hardware sprite can either be 16x16 pixels or 32x32 pixels, and the
tile bitplanes are also layed out as 4 or 16 consecutive 8x8 tiles in the
sprite tile ROMs. This means a 16x16 byte needs 96 bytes, and a 32x32 sprite
a whopping 384 bytes in the tile ROMs. The sprite decoder is explained in
detail below.

To get a better idea what the tile bitplanes look like, I wrote a little
C program to convert the tile ROMs into PNG files (with the 3 bits per 
pixel converted into 8 levels of grey). This is an 8x8 tile visualization,
not how the tile data is actually arranged in memory (the 8 bytes that make
up a tile bitplane are packed into consecutive memory locations, creating a
PNG from that would just create an unrecognizeable pixel mess).

This is the foreground layer tile ROM. You can see the numbers and text
font data, the platform tiles, bombs (split in half), parts of the 
Bomb Jack splash screen logo, and the score multiplier numbers that 
appear at the top of the screen (btw, everything is 90 degree rotated
because the screen is rotated):

![Bomb Jack Foreground Tile ROM]({{ site.url }}/images/bombjack_tilerom_fg.png)

Next the background tile ROM, this doesn't look very recognizeable because
what you see is the 8x8 tile decoding of 16x16 tiles. Each 16x16 tile
is created from four neighbouring 8x8 tiles. But it's possible to recognize
the fairly regular pieces for the greek temple on map 2, the castle
on map 3 and the sky scrapers on map 4.

![Bomb Jack Background Tile ROM]({{ site.url }}/images/bombjack_tilerom_bg.png)

And finally the sprite tile ROM. It looks like all the animated 16x16 sprites
take up the upper half, and the 32x32 sprites the lower half.

![Bomb Jack Sprite Tile ROM]({{ site.url }}/images/bombjack_tilerom_sprites.png)

An interesting quirk of the Bomb Jack splash screen is that the logo is
constructed from foreground tiles and sprites, I guess the developers were
running out of foreground tile ROM, but had some space to spare in the 
sprite ROM:

![Bomb Jack Splash 1]({{ site.url }}/images/bombjack_splash_1.png)
![Bomb Jack Splash 2]({{ site.url }}/images/bombjack_splash_2.png)
![Bomb Jack Splash 3]({{ site.url }}/images/bombjack_splash_3.png)

## The Sprite Hardware

The Bomb Jack sprite hardware is very powerful compared to what was available
at the time:

- up to 24 hardware sprites can be rendered
- sprites can be 16x16 or 32x32 pixels
- each sprite can choose one of 16 '8-color-slots' in the color palette
- sprites have a per-pixel color resolution
- each sprite can be vertically and horizontally flipped
- each sprite can select one of 128 hardwired sprite images in ROM (this
is actually a restriction compared to most home computers with sprite
hardware)

The pixel- and color-decoding of the sprite system uses the same basic 8x8
tile decoding that's also used in the background- and foreground-layer.

The sprite attributes are mapped into the address range 0x9820 to 0x987F,
96 bytes, 4 bytes per sprite. As far as I know this is a write-only area,
there are no CPU read accesses happening on this memory range.

Each sprite is described by 4 bytes:

- **Byte 0**:
    - **Bit 7**: if set, this is a 32x32 sprite, otherwise 16x16
    - **Bits 6..0**: 7 bits to define the tile code for the sprite, used
      to look up the sprite's image bitplanes in the tile ROMs
- **Byte 1**:
    - **Bit 7**: if set, the sprite is horizontally flipped
    - **Bit 6**: if set, the sprite is vertically flipped
    - **Bits 3..0**: 4 bits to provide the color value for the tile decoder
- **Byte 2**: the sprite's X position on screen
- **Byte 3**: the sprite's Y position on screen

It's unclear what the bits 4 and 5 of byte 1 do, a comment in MAME
has this to say:

```
 e        ? (set when big sprites are selected)
 f        ? (set only when the bonus (B) materializes?)
```

## The Sound Board

TODO

## The Sound Command Latch

TODO

